# LivePortrait: Audio-Driven Talking Head Version ğŸ™ï¸

## ğŸ” é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®åŸºäº [LivePortrait](https://github.com/KwaiVGI/LivePortrait) â€”â€” ä¸€ä¸ªé«˜æ•ˆçš„å›¾åƒé©±åŠ¨å¼äººåƒåŠ¨ç”»ç”Ÿæˆæ–¹æ³•ï¼Œæ”¯æŒé€šè¿‡è¾“å…¥é©±åŠ¨å›¾åƒæ¥æ§åˆ¶æºå›¾åƒçš„è¡¨æƒ…å’Œå§¿æ€ã€‚æˆ‘ä»¬åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œäº†æ‰©å±•ï¼Œå¼€å‘äº†ä¸€ä¸ª **éŸ³é¢‘é©±åŠ¨ç‰ˆæœ¬**ï¼Œå®ç°äº†ä»è¯­éŸ³åˆ°åŠ¨æ€äººåƒçš„å®æ—¶ç”Ÿæˆã€‚


### âœ¨ æ ¸å¿ƒå·¥ä½œ

æˆ‘ä»¬çš„**éŸ³é¢‘é©±åŠ¨ç‰ˆæœ¬çš„ LivePortrait**ï¼Œå¯ä»¥å®ç°ä»è¯­éŸ³ä¿¡å·ç›´æ¥ç”Ÿæˆäººè„¸åŠ¨ç”»ï¼Œå…·ä½“æ”¹è¿›åŒ…æ‹¬ï¼š

- **éŸ³é¢‘ç¼–ç æ¨¡å—**ï¼šå¼•å…¥äº†éŸ³é¢‘ç¼–ç å™¨ï¼ˆWhisperï¼‰ï¼Œå°†è¾“å…¥è¯­éŸ³è½¬æ¢ä¸ºæ—¶åºç‰¹å¾è¡¨ç¤ºã€‚
- **å…³é”®ç‚¹é¢„æµ‹**ï¼šä»¥æµåŒ¹é…ï¼ˆFlowMatchingï¼‰çš„æ–¹å¼ï¼Œè®­ç»ƒäº†ä¸€ä¸ªè½»é‡çº§çš„Transformerï¼Œæ ¹æ®æ—¶åºéŸ³é¢‘ç‰¹å¾æ¡ä»¶ï¼Œç”Ÿæˆå¯¹åº”é¢éƒ¨åŠ¨ä½œçš„å…³é”®ç‚¹è¿åŠ¨åºåˆ—ï¼ˆå…³é”®ç‚¹çš„å®šä¹‰è¯·å‚ç…§è®ºæ–‡ç¬¬ä¸‰èŠ‚ï¼š[arxiv](https://arxiv.org/pdf/2407.03168)ï¼‰ã€‚
- **æ¨ç†ç»“æ„**ï¼šåœ¨ä¿æŒä½å»¶è¿Ÿçš„å‰æä¸‹ï¼Œå°†å…³é”®ç‚¹é¢„æµ‹ç½‘ç»œä¸LivePortraité¢„è®­ç»ƒç»„ä»¶ç›¸ç»“åˆï¼Œå®ç°å®æ—¶éŸ³é¢‘é©±åŠ¨åŠ¨ç”»ç”Ÿæˆã€‚

### ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥éŸ³é¢‘é©±åŠ¨ç‰ˆæœ¬å¯ç”¨äºä»¥ä¸‹åº”ç”¨ï¼š

- æ•°å­—äººè¯­éŸ³äº¤äº’
- åŠ¨ç”»é…éŸ³ä¸è‡ªåŠ¨å£å‹åŒ¹é…
- AI å®¢æœç”Ÿæˆç­‰

---

## ğŸ§° ä½¿ç”¨è¯´æ˜

æœ¬é¡¹ç›®ä¾èµ–äºåŸå§‹ LivePortrait çš„æ¨¡å‹ç»“æ„ä¸éƒ¨åˆ†ä»£ç åº“ï¼Œè¯·å…ˆç¡®ä¿å·²æ­£ç¡®å®‰è£…å¹¶é…ç½®å¥½ç¯å¢ƒã€‚ï¼ˆå®‰è£…ç¯å¢ƒéƒ¨åˆ†è¯´æ˜æ¥è‡ªLivePortraitåŸä»“åº“ï¼‰

### 1. å…‹éš†ä»£ç å’Œå®‰è£…è¿è¡Œç¯å¢ƒ ğŸ› ï¸

> [!Note]
> ç¡®ä¿æ‚¨çš„ç³»ç»Ÿå·²å®‰è£…[`git`](https://git-scm.com/)ã€[`conda`](https://anaconda.org/anaconda/conda)å’Œ[`FFmpeg`](https://ffmpeg.org/download.html)ã€‚æœ‰å…³FFmpegå®‰è£…çš„è¯¦ç»†ä¿¡æ¯ï¼Œè§[**å¦‚ä½•å®‰è£…FFmpeg**](assets/docs/how-to-install-ffmpeg.md)ã€‚

```bash
git clone https://github.com/KwaiVGI/LivePortrait
cd LivePortrait

# ä½¿ç”¨condaåˆ›å»ºç¯å¢ƒ
conda create -n LivePortrait python=3.10
conda activate LivePortrait
```

é¦–å…ˆï¼Œé€šè¿‡ä»¥ä¸‹å‘½ä»¤æ£€æŸ¥æ‚¨å½“å‰çš„CUDAç‰ˆæœ¬ï¼š

```bash
nvcc -V # example versions: 11.1, 11.8, 12.1, etc.
```

ç„¶åï¼Œå®‰è£…ç›¸åº”ç‰ˆæœ¬çš„torchã€‚ä»¥ä¸‹æ˜¯ä¸åŒCUDAç‰ˆæœ¬çš„ç¤ºä¾‹ã€‚å¦‚æœæ‚¨çš„CUDAç‰ˆæœ¬æœªåˆ—å‡ºï¼Œè¯·è®¿é—®[PyTorchå®˜æ–¹ç½‘ç«™](https://pytorch.org/get-started/previous-versions)è·å–å®‰è£…å‘½ä»¤ï¼š
```bash
# for CUDA 11.1
pip install torch==1.10.1+cu111 torchvision==0.11.2 torchaudio==0.10.1 -f https://download.pytorch.org/whl/cu111/torch_stable.html
# for CUDA 11.8
pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 --index-url https://download.pytorch.org/whl/cu118
# for CUDA 12.1
pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 --index-url https://download.pytorch.org/whl/cu121
# ...
```


æœ€åï¼Œå®‰è£…å…¶ä½™ä¾èµ–é¡¹ï¼š

```bash
pip install -r requirements.txt
```


### 2. ä¸‹è½½é¢„è®­ç»ƒçš„LivePortriatç»„ä»¶æƒé‡ ğŸ“¥

ä»HuggingFaceä¸‹è½½é¢„è®­ç»ƒæƒé‡çš„æœ€ç®€å•æ–¹æ³•æ˜¯ï¼š
```bash
# !pip install -U "huggingface_hub[cli]"
huggingface-cli download KwaiVGI/LivePortrait --local-dir pretrained_weights --exclude "*.git*" "README.md" "docs"
```

è‹¥æ‚¨ä¸èƒ½è®¿é—®HuggingFaceå¹³å°ï¼Œä½ å¯ä»¥è®¿é—®å…¶é•œåƒç½‘ç«™[hf-mirror](https://hf-mirror.com/)è¿›è¡Œä¸‹è½½æ“ä½œï¼š

```bash
# !pip install -U "huggingface_hub[cli]"
export HF_ENDPOINT=https://hf-mirror.com
huggingface-cli download KwaiVGI/LivePortrait --local-dir pretrained_weights --exclude "*.git*" "README.md" "docs"
```

æˆ–è€…ï¼Œæ‚¨å¯ä»¥ä»[Google Drive](https://drive.google.com/drive/folders/1UtKgzKjFAOmZkhNK-OYT0caJ_w2XAnib)æˆ–[ç™¾åº¦äº‘](https://pan.baidu.com/s/1MGctWmNla_vZxDbEp2Dtzw?pwd=z5cn)ï¼ˆè¿›è¡Œä¸­ï¼‰ä¸‹è½½æ‰€æœ‰é¢„è®­ç»ƒæƒé‡ã€‚è§£å‹å¹¶å°†å®ƒä»¬æ”¾ç½®åœ¨`./pretrained_weights`ç›®å½•ä¸‹ã€‚


### 3. ä¸‹è½½éŸ³é¢‘ç¼–ç å™¨æƒé‡ï¼ˆWhisperï¼‰
é¦–å…ˆä¸‹è½½Whispe_tinyæƒé‡æ–‡ä»¶ï¼š[Whisper](https://openaipublic.azureedge.net/main/whisper/models/65147644a518d12f04e32d6f3b26facc3f8dd46e5390956a9424a650c0ce22b9/tiny.pt)

ç„¶ååœ¨`./pretrained_weights`ç›®å½•ä¸‹åˆ›å»º`audio_processor`å­ç›®å½•ï¼Œå°†æƒé‡æ–‡ä»¶æ”¾åœ¨`./pretrained_weights/audio_processor`ç›®å½•ä¸‹

ç¡®ä¿ç›®å½•ç»“æ„å¦‚æ‰€ç¤ºåŒ…å«[**æœ¬ä»“åº“è¯¥è·¯å¾„**](assets/docs/directory-structure.md)å…¶ä¸­å±•ç¤ºçš„å†…å®¹ã€‚


### 4. è®­ç»ƒæ¨¡å‹
æœ¬é¡¹ç›®æ‰€ä½¿ç”¨çš„è®­ç»ƒæ•°æ®é›†ä¸ºMEADï¼Œæ˜¯ä¸€ä¸ªåŒ…å« 60 åæ¼”å‘˜åœ¨å…«ç§ä¸åŒæƒ…ç»ªï¼ˆä¸å«ä¸­æ€§ï¼‰çš„ä¸‰ç§ä¸åŒå¼ºåº¦ä¸‹è¿›è¡Œå¯¹è¯çš„é¢éƒ¨è§†é¢‘æ•°æ®é›†ã€‚å¦‚æœæ‚¨æœ‰éœ€è¦ï¼Œå¯ä»¥å‚ç…§[MEAD](https://wywu.github.io/projects/MEAD/MEAD.html)è·å–æ›´è¯¦ç»†çš„ä¿¡æ¯ã€‚

åœ¨ä¸‹è½½æ•°æ®é›†åï¼Œå¯ä»¥é€šè¿‡process_data_MEAD.pyæ¥å¯¹MEADè¿›è¡Œå¤„ç†ï¼Œå¾—åˆ°è®­ç»ƒæ•°æ®é›†ï¼š
```bash
python process_data_MEAD.py  \
  --dataset_path your_path/MEAD  \        # MEADåŸå§‹æ•°æ®è·¯å¾„
  --output_path your_path/processed_MEAD  # å¤„ç†æ•°æ®çš„ä¿å­˜è·¯å¾„
```

ä¹‹åä¾¿å¯ä»¥å¯åŠ¨è®­ç»ƒä»£ç ï¼š
```bash
python train.py -dataset_path your_path/processed_MEAD --work_dir output
```
æ‚¨å¯ä»¥å‚ç…§è®­ç»ƒå‚æ•°æ–‡ä»¶ï¼Œå®ç°æ›´å¤šå‚æ•°çš„è°ƒèŠ‚[config](src/config/train_config.py)

### 5. æ¨ç†

ä½¿ç”¨æ¨ç†ä»£ç ï¼ŒåŠ è½½é¢„è®­ç»ƒçš„æ¨¡å‹ï¼Œå¯ä»¥è½»æ¾è·å¾—éŸ³é¢‘é©±åŠ¨ä¸‹çš„äººè„¸åŠ¨ç”»ã€‚

æ‚¨éœ€è¦æŒ‡å®š`--statistic_path`æ¥ç¡®å®šæ¨¡å‹é¢„æµ‹æ—¶æ‰€ä½¿ç”¨çš„æ•°æ®åˆ†å¸ƒå‡å€¼å’Œæ–¹å·®ï¼Œå¦‚æœæ‚¨ä½¿ç”¨process_data_MEAD.pyå¤„ç†æ•°æ®é›†ï¼Œåˆ™å¯¹åº”çš„ç»Ÿè®¡æ–‡ä»¶è·¯å¾„ä¸º`.../processed_MEAD/statistic.pt`ã€‚

æ‚¨è¿˜éœ€è¦æŒ‡å®š`--pretrained_model_path`æ¥åŠ è½½é¢„è®­ç»ƒçš„æ¨¡å‹ã€‚

å…¶å®ƒå‚æ•°çš„å«ä¹‰ï¼š

- `-s`ï¼šå‚è€ƒäººè„¸å›¾åƒè·¯å¾„
- `-d`ï¼šé©±åŠ¨éŸ³é¢‘è·¯å¾„
- `-o`ï¼šç”Ÿæˆç»“æœå­˜æ”¾è·¯å¾„
- `seed`ï¼šéšæœºç§å­ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸º0ï¼‰
- `cfg_scale`ï¼šå¼•å¯¼ç³»æ•°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸º4.5ï¼‰
- `output_fps`ï¼šè¾“å‡ºè§†é¢‘å¸§ç‡ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸º30ï¼‰

```bash
python inference_with_audio.py \
  -s assets/examples/source/s9.jpg \
  -d assets/examples/driving/angry.m4a \
  -o generated \
  --statistic_path your_statistic_path \
  --pretrained_model_path your_model_path
```


## è‡´è°¢
æˆ‘ä»¬éå¸¸æ„Ÿè°¢[LivePortrait](https://github.com/KwaiVGI/LivePortrait), [Whisper](https://github.com/openai/whisper)å’Œ[MMAudio](https://github.com/hkchengrex/MMAudio)ï¼Œæ„Ÿè°¢ä»–ä»¬çš„å¼€æ”¾ç ”ç©¶å’Œè´¡çŒ®ã€‚
